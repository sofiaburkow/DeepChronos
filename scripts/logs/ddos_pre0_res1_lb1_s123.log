/home/sofia/Desktop/Thesis/DeepChronos/.venv/lib/python3.10/site-packages/deepproblog/semiring/graph_semiring.py:77: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)
  return -self.eps <= float(a) <= self.eps

Preparing datasets (resampled)...

Preparing ddos train' dataset...
Original label distribution (train): Counter({np.int64(0): 55178, np.int64(1): 20252, np.int64(2): 20252, np.int64(3): 20252, np.int64(4): 20252, np.int64(5): 20252})
Loading cached train dataset from /home/sofia/Desktop/Thesis/DeepChronos/src/DARPA/data/cache/train_ddos_resampled.pkl
Label distribution: Counter({'no_alarm': 136186, 'alarm': 20252})

Preparing ddos test' dataset...
Original label distribution (test): Counter({np.int64(0): 36785, np.int64(5): 13502, np.int64(3): 14, np.int64(2): 9, np.int64(4): 9, np.int64(1): 8})
Loading cached test dataset from /home/sofia/Desktop/Thesis/DeepChronos/src/DARPA/data/cache/test_ddos_resampled.pkl
Label distribution: Counter({'no_alarm': 36825, 'alarm': 13502})

Using pretrained models: False

Caching ACs
Training  for 1 epoch(s)
Epoch 1
Iteration:  100 	s:3.4380 	Average Loss:  0.24573355957801243
Iteration:  200 	s:3.3066 	Average Loss:  0.2337253116879782
Iteration:  300 	s:3.2180 	Average Loss:  0.20389683654468352
Iteration:  400 	s:3.2312 	Average Loss:  0.19957911733388176
Iteration:  500 	s:3.1763 	Average Loss:  0.19694211145508322
Iteration:  600 	s:3.1733 	Average Loss:  0.19433280679217152
Iteration:  700 	s:3.2255 	Average Loss:  0.20390251716710572
Iteration:  800 	s:3.0348 	Average Loss:  0.1830049366086289
Iteration:  900 	s:3.2569 	Average Loss:  0.19794400462431652
Iteration:  1000 	s:3.5566 	Average Loss:  0.19300349044243575
Iteration:  1100 	s:3.6236 	Average Loss:  0.19681452445309003
Iteration:  1200 	s:6.8933 	Average Loss:  0.19477793764630433
Iteration:  1300 	s:6.8844 	Average Loss:  0.1973340106364615
Iteration:  1400 	s:7.5280 	Average Loss:  0.1923466028858563
Iteration:  1500 	s:13.7718 	Average Loss:  0.18896575614323083
Iteration:  1600 	s:14.0928 	Average Loss:  0.19345577051056703
Iteration:  1700 	s:14.1845 	Average Loss:  0.20185608746656647
Iteration:  1800 	s:14.0132 	Average Loss:  0.19361845219542065
Iteration:  1900 	s:14.2317 	Average Loss:  0.19340540085633295
Iteration:  2000 	s:14.2051 	Average Loss:  0.19482338480626943
Iteration:  2100 	s:14.3540 	Average Loss:  0.19447687557436402
Iteration:  2200 	s:14.4255 	Average Loss:  0.1952174112675875
Iteration:  2300 	s:14.0799 	Average Loss:  0.1897670172341989
Iteration:  2400 	s:14.3389 	Average Loss:  0.1953242179504176
Iteration:  2500 	s:14.5184 	Average Loss:  0.19267999745985198
Iteration:  2600 	s:14.1205 	Average Loss:  0.19327944084246396
Iteration:  2700 	s:14.4138 	Average Loss:  0.20207848572276402
Iteration:  2800 	s:13.9043 	Average Loss:  0.18950363733173337
Iteration:  2900 	s:14.8197 	Average Loss:  0.20344242431957807
Iteration:  3000 	s:14.3835 	Average Loss:  0.20181806706207472
Iteration:  3100 	s:14.1531 	Average Loss:  0.19161014897062537
Epoch time:  303.7413125038147
Accuracy:  0.7317145866036123
