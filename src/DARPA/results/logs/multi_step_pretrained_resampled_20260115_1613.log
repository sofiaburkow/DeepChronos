#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#Accuracy 0.7317344566534862
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase1	phase2	phase3	phase4	phase5
#         	benign	 36785	     0	     0	     0	     0	 13501
#         	phase1	     0	     8	     0	     0	     0	     0
#Predicted	phase2	     0	     0	     9	     0	     0	     0
#         	phase3	     0	     0	     0	    14	     0	     0
#         	phase4	     0	     0	     0	     0	     9	     0
#         	phase5	     0	     0	     0	     0	     0	     1
i,time,loss,ground_time,compile_time,eval_time
100,5.210407018661499,0.2500450834585319,0.0010213905334472333,0.006555310726165684,0.00015017647743225106
200,12.481854915618896,0.21340149090129562,0.0010188847541808725,0.00662147345542899,0.00021923170089721683
300,21.293217420578003,0.2178737407517955,0.0010308068752288464,0.006633413362502938,0.00027580780982971185
400,29.26571774482727,0.20178006286200326,0.00102565755844113,0.006601732683181677,0.00024512872695922887
500,38.14568901062012,0.2002433824462161,0.0010219877243041633,0.006411445236205974,0.00026464953422546377
600,46.819849491119385,0.20765701572203019,0.0010338222026824596,0.006658095550537016,0.0002582505702972414
700,56.29484963417053,0.19788995967152068,0.0010250979423522609,0.006493403911590487,0.00027908959388732826
800,65.25217461585999,0.19342812814487387,0.0010378998756408323,0.006742784404754558,0.0002677234649658205
900,74.2151780128479,0.19204259550592123,0.0010197577953338275,0.006491258287429726,0.0002681329727172851
1000,82.96574449539185,0.20349743503196951,0.0010248150348662961,0.0065011534214019055,0.0002623996257781982
1100,91.34710383415222,0.1940152179171054,0.001041574287414517,0.006748573780059702,0.00025162739753723114
1200,100.4320056438446,0.1996402592033379,0.0010469607353210094,0.006772180271148576,0.00026851105690002487
1300,122.15205574035645,0.1949414984848943,0.001034685993194542,0.006636341762542641,0.0006431431293487555
1400,150.37133979797363,0.20003806784486453,0.0010256280422210337,0.006590508222579882,0.0008364470481872549
1500,179.37702083587646,0.19697688207185082,0.001030662488937343,0.006582656574249184,0.0008642358303070069
1600,206.15199875831604,0.18738047901931298,0.0010315354824065855,0.00653515839576712,0.0007934511184692388
1700,233.94242596626282,0.18706452574870955,0.0010242266178130716,0.006667495536804129,0.0008257290363311773
1800,261.99305534362793,0.20234049040664406,0.0010279198646545042,0.006565575838088884,0.0008331552505493142
1900,289.6908402442932,0.1892898474191196,0.0010219402313232074,0.006478424310684109,0.0008271359443664573
2000,319.92190980911255,0.19254029039748566,0.001023398971557578,0.006418401432037273,0.0009078673362731925
2100,338.37094140052795,0.19771099810776652,0.0010313373565673481,0.006526564025878792,0.0005597277164459223
2200,347.9265031814575,0.19394341197775725,0.0010375615596770848,0.006553563404083179,0.00027728853225708074
2300,376.1735157966614,0.19934371016823652,0.0010335065364837303,0.006516377162933225,0.0008325338363647432
2400,403.12921023368835,0.1955337886399646,0.0010340462207793861,0.006631536817550557,0.0008086262702941866
2500,411.46640944480896,0.18804018155867788,0.0010289014816283755,0.00665705800056449,0.0002422354221343992
2600,419.33029341697693,0.20205999804432295,0.0010399364471435192,0.006707900524139294,0.00022678189277648925
2700,427.0347044467926,0.1979207553362796,0.0010322454929351426,0.006574954223632721,0.0002205094337463378
2800,436.23216128349304,0.19800840935278863,0.0010410452842712025,0.006736403703689477,0.0002684636592864997
2900,445.45915031433105,0.19412957021576405,0.001030674839019737,0.00654467201232902,0.00027045164108276365
3000,455.7794077396393,0.1930568324824651,0.0010387295722961056,0.006686997461318862,0.00029284577369689905
3100,467.4237277507782,0.18806739268140496,0.0010295842647552122,0.0066714909076689664,0.0003374270915985094