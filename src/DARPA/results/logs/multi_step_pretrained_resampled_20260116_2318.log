#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#Accuracy 0.7317344566534862
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase1	phase2	phase3	phase4	phase5
#         	benign	 36785	     0	     0	     0	     0	 13501
#         	phase1	     0	     8	     0	     0	     0	     0
#Predicted	phase2	     0	     0	     9	     0	     0	     0
#         	phase3	     0	     0	     0	    14	     0	     0
#         	phase4	     0	     0	     0	     0	     9	     0
#         	phase5	     0	     0	     0	     0	     0	     1
i,time,loss,ground_time,compile_time,eval_time
100,8.605364322662354,0.24496327337824503,0.0013757786273955793,0.009452229738235526,0.0002375211238861088
200,17.027931451797485,0.21843243697348683,0.001387262535095166,0.009389003849029624,0.0002378863811492916
300,25.18412733078003,0.2078578594202739,0.0013848933696746315,0.0095988770008088,0.00022850041389465333
400,33.2446813583374,0.20818989337463886,0.0013915587902068572,0.009587650728225788,0.00022437744140624966
500,41.27428698539734,0.21204716302468024,0.001390465211868234,0.009499154233932591,0.00022353334426879822
600,49.315059423446655,0.20120329211017343,0.0013887903690337614,0.009345850563049382,0.00022252240180969197
700,57.54536509513855,0.19978472556748067,0.0013880231857299238,0.009292905235290605,0.00022600202560424834
800,65.74157977104187,0.197963384687886,0.0013852466583251474,0.009550658941269,0.00022344279289245592
900,73.97154951095581,0.19126017770069087,0.0013889743328093945,0.009576248979568576,0.00022460093498229944
1000,82.31034421920776,0.19431155677122963,0.0013879878997802239,0.009427334308624339,0.00022624106407165487
1100,90.58557033538818,0.20271592726754842,0.0013866784572600774,0.009468274164199897,0.00022534594535827612
1200,98.77850842475891,0.19772021199711975,0.00139404740333552,0.00983300571441658,0.0002235325813293456
1300,106.95586085319519,0.19660124366639034,0.001391381168365427,0.009494700622558683,0.00022207231521606435
1400,115.17147445678711,0.19384935930548364,0.001389994907379098,0.00956128644943246,0.00022349972724914523
1500,123.30119895935059,0.1985319531818569,0.0013908092975615939,0.009490911722183304,0.00022232327461242722
1600,131.4779143333435,0.19279759208276823,0.001388696622848457,0.009631967210769731,0.00022322864532470774
1700,139.73348331451416,0.1955994937570382,0.0013921665668487038,0.009669870758056727,0.00022534227371215796
1800,147.86112475395203,0.19434546455947369,0.001388482761383003,0.009447045850753844,0.00022151079177856503
1900,156.08770203590393,0.19640556850010576,0.001387979459762525,0.00947957634925849,0.00022458281517028826
2000,164.20642137527466,0.19614161833887167,0.0013889998435973622,0.009474572896957478,0.0002216197967529299
2100,172.3381667137146,0.19741313615050363,0.0013939736366271487,0.009699095869064424,0.0002222701072692867
2200,180.47113180160522,0.19529501413591427,0.0013875268936156728,0.009494367027282784,0.00022238283157348634
2300,188.6092655658722,0.19994645721553028,0.0013924772739409854,0.009556350612640478,0.00022294664382934662
2400,196.81435561180115,0.19165895894901955,0.0013894000053405243,0.009446473312378013,0.00022493114471435537
2500,205.00910758972168,0.19257878393218975,0.0013875833034514909,0.009455508899688785,0.00022489280700683617
2600,213.1206123828888,0.1909179298901921,0.0013887631416320246,0.009502713155746545,0.00022113571166992185
2700,221.3147509098053,0.19314062566136886,0.0013892087459563692,0.009678143596649222,0.00022418961524963457
2800,229.4878396987915,0.19067816839684568,0.0013895364761352064,0.009627739572525081,0.0002228815555572506
2900,237.70247101783752,0.19528233181542567,0.0013854485988616435,0.009551355361938551,0.00022462863922119165
3000,245.87564873695374,0.18952377199203208,0.0013874290943145223,0.009499093818664608,0.0002231774806976324
3100,254.05763745307922,0.19681678916202397,0.0013926416873931344,0.00978037166595467,0.000223768854141236