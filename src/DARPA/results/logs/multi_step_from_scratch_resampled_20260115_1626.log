#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#Accuracy 0.7316549764539909
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase1	phase2	phase3	phase4	phase5
#         	benign	 36784	     0	     0	     0	     2	 13502
#         	phase1	     0	     8	     0	     0	     0	     0
#Predicted	phase2	     1	     0	     9	     0	     0	     0
#         	phase3	     0	     0	     0	    14	     0	     0
#         	phase4	     0	     0	     0	     0	     7	     0
#         	phase5	     0	     0	     0	     0	     0	     0
i,time,loss,ground_time,compile_time,eval_time
100,8.85290265083313,0.3580131492277724,0.000862011098861699,0.006358111715316789,0.00026958727836608935
200,17.250458002090454,0.23395497207849814,0.0008716824054718071,0.006740092849731468,0.0002590527534484855
300,25.448559999465942,0.20078436916935544,0.0008728223800659239,0.006471617460250853,0.0002549625873565673
400,33.394938468933105,0.20100698789853275,0.000873826599121098,0.006877138566970849,0.00024744591712951675
500,41.60726189613342,0.19405966255551363,0.0008736394882202203,0.006726114320755046,0.0002528325557708739
600,50.04518413543701,0.20092903655791283,0.0008703534603118942,0.006743363142013557,0.0002589069366455076
700,58.138453245162964,0.2072594964071794,0.0008717495441436806,0.0067795354366302655,0.0002490503787994386
800,66.22106218338013,0.20111253453801162,0.0008735541820526162,0.006797339296340982,0.000249037790298462
900,74.1559579372406,0.2011760437072624,0.0008738082885742242,0.006914525270462081,0.00024317502975463836
1000,82.45866990089417,0.19991688226016183,0.0008732595443725595,0.006694185304641713,0.00025399150848388685
1100,90.59777164459229,0.1971128786930458,0.0008743031501770095,0.00677931880950931,0.00025088505744934054
1200,98.8796169757843,0.19205915220086944,0.0008704319477081377,0.006574878358840925,0.0002530611038208015
1300,107.6048972606659,0.19013883156259298,0.0008733342647552503,0.006693539142608661,0.0002640716552734372
1400,116.92869687080383,0.1920142137623971,0.0008736819744110197,0.006700463151931813,0.00027684350013732883
1500,125.88684344291687,0.19550385909670026,0.0008699400424957309,0.006833793592453007,0.000264667272567749
1600,135.50923418998718,0.1953246336777209,0.0008720445156097459,0.006854616880416917,0.0002816995620727534
1700,144.83805513381958,0.19471147857603457,0.0008742352485656791,0.0067134877681732505,0.0002747324466705313
1800,154.24255919456482,0.2007518128225836,0.0008734526157379189,0.006880066204071078,0.0002767980575561522
1900,163.5764982700348,0.1983598252848742,0.0008724354267120386,0.006737573432922396,0.00027970438003540037
2000,172.26751947402954,0.19176529448762777,0.0008715583324432419,0.0066594227790832536,0.0002604141235351562
2100,181.72196006774902,0.19991550168632208,0.0008737033843994198,0.006751618242263807,0.00027434253692626935
2200,191.00988578796387,0.19388215790889532,0.0008739996910095268,0.006864902305603056,0.0002732094764709473
2300,200.31894826889038,0.19586134918787285,0.0008715413570404101,0.006793905353546168,0.0002754811286926261
2400,209.1319773197174,0.19727419035983002,0.0008734684467315697,0.0067660263061523705,0.0002644463062286375
2500,217.45632982254028,0.1962853377670581,0.0008733139038085974,0.006814837789535558,0.0002522939205169681
2600,226.2156171798706,0.19431800205500419,0.0008742084026336684,0.006869700670242365,0.0002633679389953615
2700,234.54655599594116,0.18742950209558715,0.000872712230682375,0.006598009920120265,0.0002525971889495847
2800,242.93654036521912,0.18677576429126824,0.0008695188045501781,0.0065413979053497405,0.0002528629302978508
2900,251.6080286502838,0.19827883225117054,0.0008723985671997093,0.00681210131645205,0.00025786409378051776
3000,259.88931679725647,0.20148772043428181,0.0008710951805114787,0.006644706630706813,0.0002460004806518561
3100,268.6624631881714,0.1944278907997363,0.000872942209243783,0.006666176414489772,0.0002633356571197509