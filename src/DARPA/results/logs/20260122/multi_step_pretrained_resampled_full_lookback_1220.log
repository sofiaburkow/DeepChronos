#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#
#=== Results for full dataset ===
#
#Accuracy: 0.7317
#Micro F1: 0.7317 | Macro F1: 0.8075 | Weighted F1: 0.6184
#
#Per-class metrics:
#  [benign] P=0.7315 | R=1.0000 | F1=0.8449 | Support=36785
#  [phase1] P=1.0000 | R=1.0000 | F1=1.0000 | Support=8
#  [phase2] P=1.0000 | R=1.0000 | F1=1.0000 | Support=9
#  [phase3] P=1.0000 | R=1.0000 | F1=1.0000 | Support=14
#  [phase4] P=1.0000 | R=1.0000 | F1=1.0000 | Support=9
#  [phase5] P=1.0000 | R=0.0001 | F1=0.0001 | Support=13502
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase1	phase2	phase3	phase4	phase5
#         	benign	 36785	     0	     0	     0	     0	 13501
#         	phase1	     0	     8	     0	     0	     0	     0
#Predicted	phase2	     0	     0	     9	     0	     0	     0
#         	phase3	     0	     0	     0	    14	     0	     0
#         	phase4	     0	     0	     0	     0	     9	     0
#         	phase5	     0	     0	     0	     0	     0	     1
i,time,loss,ground_time,compile_time,eval_time
100,7.59356427192688,0.2451241791555136,0.0014842615604400502,0.01018395504951473,0.00020856771469116202
200,15.8576021194458,0.22515991715702938,0.0014993783473968368,0.010552541637420636,0.00023015866279602027
300,24.05736756324768,0.21446043656267694,0.0014987189292907548,0.010466327714920017,0.00022834897041320798
400,32.33689284324646,0.2077228099561147,0.0015015213012695172,0.010602214956283525,0.00023074088096618642
500,40.66102623939514,0.20317329120023384,0.001497454690933215,0.010737595844268786,0.00023233981132507307
600,48.838197231292725,0.1902262323779614,0.0014981793880462443,0.010400929737090996,0.0002269530773162838
700,57.12372636795044,0.1916571286673392,0.001500147628784167,0.010548263978958108,0.00022995662689208958
800,65.62398886680603,0.19731808820231195,0.0014984729766845516,0.010554425048828102,0.00023830032348632848
900,79.26200008392334,0.19872316530735532,0.0014981732368469097,0.010501651382446242,0.000363998603820801
1000,97.49262404441833,0.1963408562080313,0.0014984298706054494,0.010640674495696991,0.0004697906017303455
1100,115.5867555141449,0.19464715789501558,0.0014995836257934436,0.010335663843154869,0.0004634356975555443
1200,124.51461100578308,0.18871950542630755,0.0014999782085418527,0.010369380760192837,0.00023916645050048888
1300,133.08377313613892,0.1894270470719076,0.001499185323715193,0.010542017984390221,0.00023145685195922775
1400,141.48938465118408,0.19690538968717416,0.0014989903926849206,0.010205166816711377,0.0002256107330322267
1500,150.33737516403198,0.19335405625501895,0.0015022224426269404,0.010422116231918277,0.00023595886230468675
1600,160.2319097518921,0.20185529554306483,0.0014979975223541064,0.010362119340896567,0.0002651966094970706
1700,171.43891620635986,0.19367187808449915,0.0015019905567169062,0.010271263933181703,0.0003085213661193855
1800,181.36011457443237,0.20159486892773892,0.0015044069290161,0.01069619736671443,0.0002684266090393057
1900,189.96861481666565,0.19805207836385347,0.0015018467903137056,0.010278452968597324,0.0002277142047882084
2000,198.6845715045929,0.1925305831579097,0.001498274707794171,0.010082714796066213,0.00023220286369323652
2100,209.9590117931366,0.19030076887992597,0.0015040657043456861,0.010162375736236523,0.00029472312927246116
2200,218.85293769836426,0.19823030169036523,0.0014986901760101164,0.010577880144119249,0.00024282140731811494
2300,227.358295917511,0.19581654912116173,0.001502676725387557,0.010530711126327483,0.0002298967838287353
2400,235.6471610069275,0.20286135953618967,0.0015002656459808155,0.010611358261108362,0.00022345046997070326
2500,244.326176404953,0.1882693077439587,0.0015033733844756888,0.010433458232879594,0.00023528394699096723
2600,255.47254467010498,0.18995230993940151,0.001500093269348128,0.010433120679855287,0.0003004840850830075
2700,264.7165262699127,0.1984090066274795,0.0014984833240508915,0.010638222169876034,0.0002511115074157722
2800,281.72331142425537,0.1888792751102472,0.0015002639293670503,0.010326001977920475,0.00043925051689147973
2900,313.4790952205658,0.18727001208579735,0.0015006708145141473,0.010377391719818068,0.000889336538314819
3000,350.1469647884369,0.19557642700726985,0.0015011770725250073,0.010638313770294132,0.0010425770759582534
3100,387.08394861221313,0.19855804876695413,0.0015012882709503005,0.010506030273437463,0.0010499442100524907