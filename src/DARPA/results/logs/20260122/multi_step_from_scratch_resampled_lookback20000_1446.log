#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#
#=== Results for full dataset ===
#
#Accuracy: 0.7307
#Micro F1: 0.7307 | Macro F1: 0.1408 | Weighted F1: 0.6173
#
#Per-class metrics:
#  [benign] P=0.7310 | R=0.9998 | F1=0.8445 | Support=36785
#  [phase1] P=0.0000 | R=0.0000 | F1=0.0000 | Support=8
#  [phase2] P=0.0000 | R=0.0000 | F1=0.0000 | Support=9
#  [phase3] P=0.0000 | R=0.0000 | F1=0.0000 | Support=14
#  [phase4] P=0.0000 | R=0.0000 | F1=0.0000 | Support=9
#  [phase5] P=0.0000 | R=0.0000 | F1=0.0000 | Support=13502
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase1	phase2	phase3	phase4	phase5
#         	benign	 36776	     2	     6	    14	     9	 13502
#         	phase1	     0	     0	     0	     0	     0	     0
#Predicted	phase2	     0	     6	     0	     0	     0	     0
#         	phase3	     9	     0	     3	     0	     0	     0
#         	phase4	     0	     0	     0	     0	     0	     0
#         	phase5	     0	     0	     0	     0	     0	     0
i,time,loss,ground_time,compile_time,eval_time
100,5.0832250118255615,13.45426264478844,0.0010458862304687973,0.008411247205734105,0.0001635499000549316
200,9.874833345413208,13.757059455487179,0.0010474088191986595,0.008697387123107789,0.00015993123054504365
300,14.794848680496216,13.791275805149926,0.001044716119766285,0.008385882091522108,0.0001632902145385742
400,19.632994413375854,13.605035061150398,0.0010471110820770779,0.008349799060821438,0.00016079339981079095
500,24.445853233337402,13.306908045837273,0.0010538053512573746,0.00840734109878527,0.00015911822319030774
600,29.023946285247803,13.59772174172612,0.0010458088397980229,0.008245236063003425,0.00015250940322875965
700,33.820810079574585,13.567784862146539,0.0010491998672485859,0.008538972902297836,0.0001584824085235593
800,38.55007886886597,13.874320723668925,0.0010445300579071534,0.008630882787704366,0.00015681500434875484
900,44.611610651016235,13.459558161825699,0.0010501268863678523,0.008655370712280138,0.0001962362766265863
1000,65.09989976882935,13.389417345110788,0.0010540148258209741,0.00851458778381336,0.0006630631446838372
1100,85.98035097122192,13.404181278851265,0.001051561450958309,0.00850538907051074,0.0006680815219879155
1200,104.2692711353302,13.258334631973215,0.001051472663879442,0.008337015342712277,0.0005853750228881835
1300,108.80172395706177,13.669759989928785,0.001047773933410693,0.008350696420669457,0.0001485027790069577
1400,113.48136878013611,13.425807513192142,0.001049032735824639,0.008374593257903944,0.00015338845252990728
1500,118.07126069068909,13.502242425844877,0.0010471405506134559,0.008187849950790303,0.0001498512744903566
1600,122.66873931884766,13.785787976688347,0.0010454516887665305,0.008397843074798484,0.00015068063735961925
1700,127.17066025733948,13.873924523152871,0.001042833328247118,0.008500187969207674,0.0001476643085479734
1800,131.85880208015442,13.18724952431737,0.0010558559894562282,0.008256557655334357,0.0001514633178710933
1900,136.37325978279114,13.74248917554167,0.0010451881885529086,0.008486551189422513,0.00014771924018859898
2000,140.92358899116516,13.50995837081875,0.001045871782302907,0.008347287988662602,0.00014922409057617183
2100,145.47517085075378,13.5021804758562,0.0010496324539185067,0.00854013786315907,0.00014896621704101507
2200,149.98208951950073,13.681163231350135,0.0010467491149902858,0.00827797379493705,0.00014846334457397424
2300,154.43983340263367,13.818134252017005,0.0010445442676544688,0.008645539331436036,0.00014729900360107423
2400,158.95166969299316,13.607389026473005,0.0010500680446625286,0.008658439588546639,0.00014865608215332063
2500,163.53760385513306,13.725624121560083,0.0010452227115631588,0.008546707582473625,0.00014974355697631845
2600,168.12743258476257,13.39940630451772,0.0010500410079956567,0.008299693298339733,0.0001506453514099119
2700,172.71058106422424,13.440955661080528,0.0010505293369293726,0.008466663980483888,0.0001499290943145751
2800,177.125262260437,13.989530518629888,0.0010370619297028108,0.008264100742340016,0.00014603910446167034
2900,181.85008597373962,13.464493677212701,0.0010491579532623805,0.008321862792968631,0.00015521869659423863
3000,186.53915810585022,13.303896060367798,0.0010570580005646256,0.008768276929855202,0.00015362024307250972
3100,191.0731053352356,13.57772126216489,0.0010435342311859632,0.008126174736022847,0.00014923214912414523