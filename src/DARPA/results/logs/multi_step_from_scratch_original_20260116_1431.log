#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#Accuracy 0.7309793947582809
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase1	phase2	phase3	phase4	phase5
#         	benign	 36785	     5	     9	    14	     9	 13502
#         	phase1	     0	     3	     0	     0	     0	     0
#Predicted	phase2	     0	     0	     0	     0	     0	     0
#         	phase3	     0	     0	     0	     0	     0	     0
#         	phase4	     0	     0	     0	     0	     0	     0
#         	phase5	     0	     0	     0	     0	     0	     0
i,time,loss,ground_time,compile_time,eval_time
100,7.831282138824463,0.6621699132025242,0.001421103429794355,0.007540353918075785,0.0002149458885192871
200,15.629929542541504,0.5408314357325434,0.0014377600669861295,0.007768320369720678,0.0002167214393615721
300,23.383806228637695,0.43843894623802043,0.001440333557128955,0.007864293670654525,0.00021543064117431684
400,31.148281574249268,0.4141861596454692,0.0014394600391388404,0.00795963940620443,0.0002150131225585934
500,38.87042164802551,0.4170764058559143,0.0014397704601288302,0.008038258457184054,0.00021372952461242662
600,47.017149925231934,0.4049884201738314,0.0014352200984955278,0.007750803756714109,0.00023312163352966366
700,54.7192497253418,0.4133692496824006,0.00143757624626164,0.007667165613174651,0.00021381464004516544
800,62.3805410861969,0.41332155315165436,0.001441566038131766,0.008010792827606434,0.00021190948486328072
900,70.04078602790833,0.4045494825710921,0.0014375037670135973,0.007880580568313816,0.00021249165534973174
1000,86.20306086540222,0.40285003590350243,0.0014353511333466077,0.008037161159515598,0.00043790802955627413
1100,29093.240436553955,0.41374762866214954,0.0014380224227905775,0.007785244512558214,0.0003918411731719973
1200,29101.511912584305,0.4052965227059576,0.0014352810382843486,0.007616057920456157,0.00023322448730468847
1300,29111.006944656372,0.40787306954691305,0.001437672948837328,0.007729074478149631,0.00027428593635559135
1400,29119.441875457764,0.4109086867113729,0.0014407024860382544,0.007724221134186015,0.00023760118484497103
1500,29127.21729183197,0.40601643219901234,0.001440078639984178,0.007976639270782696,0.0002197991847991947