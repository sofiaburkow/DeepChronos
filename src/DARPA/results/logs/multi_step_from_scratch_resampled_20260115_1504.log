#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#Accuracy 0.7313453591862683
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase5	phase1	phase2	phase3	phase4
#         	benign	 36770	 13506	     0	     0	     0	     1
#         	phase5	     0	     0	     0	     0	     0	     0
#Predicted	phase1	     0	     0	     9	     0	     0	     0
#         	phase2	     1	     0	     0	    11	     0	     0
#         	phase3	     5	     0	     0	     0	    16	     0
#         	phase4	    10	     0	     0	     0	     0	     7
i,time,loss,ground_time,compile_time,eval_time
100,27.76803684234619,0.31883555796759994,0.0009743261337280358,0.001979527807235767,0.0008414168834686282
200,55.13403677940369,0.2126598585973437,0.0009829677581787235,0.0020157101631165077,0.000844019746780394
300,83.49163055419922,0.2122694684629627,0.000985629034042369,0.0020206607818604016,0.000888873863220213
400,111.85516095161438,0.18913857274451892,0.0009751295566558957,0.001891503620147752,0.0008874932765960681
500,140.34742999076843,0.19343173444465334,0.0009837643146514991,0.0019808755397797135,0.0008835008621215802
600,168.29558992385864,0.18878540837964408,0.000989672708511367,0.002058482646942194,0.0008607685089111342
700,196.30476093292236,0.18918080304291274,0.000977842521667491,0.0020081454277039064,0.0008600767135620114
800,224.2875463962555,0.1778080384395104,0.0009777413368225192,0.0019746215820312966,0.0008580311775207536
900,252.0232801437378,0.18277511281381373,0.000985630846023572,0.0020098500728607653,0.0008372740745544425
1000,280.7278425693512,0.18465435505218575,0.0009802369117736921,0.0020101722240448553,0.0008710641384124724
1100,309.0820264816284,0.1854855561613515,0.000977036285400404,0.0020015509128571128,0.0008495728015899664
1200,327.8962514400482,0.17676101098621658,0.0009818230628967398,0.002038254690170338,0.0005397736072540273
1300,342.0674068927765,0.185638396540821,0.0009788932800293096,0.0020248768806458,0.0003853525161743169
1400,356.98500299453735,0.18367564632814948,0.0009857223987579438,0.002046556091308641,0.00040782184600830085
1500,372.0140793323517,0.1922859028642408,0.00097892565727235,0.001985696411132862,0.00040880599021911714
1600,385.61428689956665,0.18576303802510638,0.0009818461418151963,0.0019820001125336146,0.0003655513763427738
1700,398.58685326576233,0.17851097280320782,0.0009844676494598496,0.0019807415008545443,0.0003570918083190932
1800,408.51305317878723,0.17945160873863147,0.0009841356754303088,0.002046829700470019,0.00029407582283020017
1900,418.5419771671295,0.18589196725896154,0.0009756705760955929,0.001956171989440972,0.0002994273662567139
2000,427.96616291999817,0.1827076366953725,0.0009775406360626327,0.0019904359817505394,0.0002809828281402587
2100,442.2213125228882,0.17562196849953568,0.0009775192737579484,0.0020215080738068135,0.0003807543754577626
2200,455.9581608772278,0.1824413316068522,0.0009793532371521099,0.0020497204780579115,0.0003702157020568847
2300,465.067645072937,0.18262642887588115,0.0009762403488159324,0.001996664476394707,0.0002781546115875241
2400,474.77321314811707,0.18433408912564483,0.0009784550189972034,0.001969497871398976,0.00029556589126586934
2500,484.1364164352417,0.18561409001474993,0.000980123090744028,0.0020407876968384295,0.0002837617397308354
2600,493.61254382133484,0.18338001362915468,0.0009828777790069699,0.0020034766197205094,0.00028994293212890597
2700,502.90521144866943,0.1878074286241832,0.0009848524570465226,0.001981120967865045,0.0002826139450073235
2800,512.6028234958649,0.17933440760661112,0.0009725150108337489,0.001961137580871633,0.0002962818622589118
2900,523.4142825603485,0.18934152442296465,0.0009750938892364612,0.0019659537792206276,0.00033181924819946355
3000,532.6578898429871,0.18295886607298562,0.0009815466880798444,0.001998464059829763,0.00028402166366577194
3100,543.424569606781,0.1846098276845537,0.0009834214210510382,0.002044722986221364,0.00032572646141052283