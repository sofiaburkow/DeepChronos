#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#Accuracy 0.7304230333618137
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase1	phase2	phase3	phase4	phase5
#         	benign	 36721	     0	     0	     0	     1	 13502
#         	phase1	     0	     8	     0	     0	     0	     0
#Predicted	phase2	    41	     0	     9	     0	     0	     0
#         	phase3	     9	     0	     0	    14	     0	     0
#         	phase4	    14	     0	     0	     0	     8	     0
#         	phase5	     0	     0	     0	     0	     0	     0
i,time,loss,ground_time,compile_time,eval_time
100,13.807437181472778,0.6032720792526379,0.002112048530578571,0.0033451983928680647,0.0003809871196746817
200,22.0942645072937,0.47005994848324917,0.002086889839172322,0.003314749908447289,0.00023133640289306693
300,30.243481397628784,0.33198497935198246,0.002065222978591878,0.0033869421482086363,0.00022803044319152848
400,65.17053818702698,0.29545823102947905,0.0021119906425475592,0.0032630795478821107,0.0009969238758087166
500,91.10848689079285,0.2777331517229322,0.002137828350067088,0.003258256340026886,0.0007845023632049564
600,99.01784873008728,0.26745312398241367,0.0021339046478271043,0.0033681014060974435,0.0002228857994079591
700,106.91722846031189,0.263215348892154,0.002123049020767168,0.0031632459640503325,0.00022298541069030756
800,120.92165279388428,0.2396168635590584,0.0021135339736938095,0.0033494160175323658,0.0004110981941223153
900,143.21926712989807,0.24927739932209078,0.002154081487655602,0.003306428098678613,0.0006644178867340081
1000,170.4358310699463,0.2412814014468131,0.0020466627120971186,0.0033491577148437824,0.0008154309272766099
1100,178.4503242969513,0.22768782335574542,0.002151567125320386,0.0032196979045868183,0.00022544894218444816
1200,186.5668499469757,0.22852219366763166,0.0021145093917846304,0.0033247236251831226,0.00022971405982971193
1300,194.51462411880493,0.23073651594378133,0.0020565402507781577,0.0032863321304321584,0.00022570376396179186
1400,202.44370985031128,0.22047841832971243,0.0020568933486938097,0.0033382774829864713,0.00022500691413879434
1500,210.39480757713318,0.21688482313519672,0.0021926177501677985,0.003182253742218048,0.00022590761184692462
1600,218.36497116088867,0.2052528711957575,0.0021666493415832093,0.0032688287258148463,0.00022647843360900936
1700,226.29296469688416,0.21243373928873552,0.0021237718582152905,0.0033912843704223842,0.00022520837783813506
1800,234.39009380340576,0.21156566728363488,0.0022201649665832064,0.003253903102874778,0.00022887439727783208
1900,242.45401215553284,0.20340945667469895,0.0021274709224700554,0.0036050467014312913,0.00022798953056335465
2000,250.45067715644836,0.1932321550039319,0.002187533903121913,0.0034342055320740004,0.00022535691261291478
2100,258.45486211776733,0.21301087297212234,0.002046185874938918,0.0032866443634033586,0.0002254949569702148
2200,266.47627544403076,0.20154226869577088,0.002137954044341999,0.003414873504638692,0.0002264587402343745
2300,274.46836590766907,0.2007022713602714,0.0021811218738555585,0.0034529052257537933,0.00022582411766052264
2400,282.4739694595337,0.2017864046528234,0.0021737603664397794,0.0033724071979523013,0.000225381946563721
2500,290.42079043388367,0.2012831777878182,0.0021273394584655357,0.0033105226516723855,0.00022662029266357447
2600,307.0926704406738,0.19334412177354807,0.0021961725234984925,0.003406301212310814,0.0004720720291137693
2700,324.05696725845337,0.19556813827527322,0.0020977226257323776,0.003443893861770655,0.00046494555473327573
2800,340.9916470050812,0.19866655608513042,0.0021523620605468337,0.003468268156051666,0.00046529507637024147
2900,357.91244554519653,0.19957324020452005,0.002065222883224452,0.0031963510990143103,0.0004652617931365972
3000,374.8520464897156,0.20046315760530148,0.002070419597625697,0.003295860528945948,0.00046529545783996566
3100,391.87772846221924,0.19573677069145162,0.0021274291992187076,0.003329138278961209,0.00046525592803955046