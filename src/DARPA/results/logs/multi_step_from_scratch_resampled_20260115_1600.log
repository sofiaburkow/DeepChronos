#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#Accuracy 0.7316351064041171
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase1	phase2	phase3	phase4	phase5
#         	benign	 36783	     0	     0	     0	     2	 13502
#         	phase1	     0	     8	     0	     0	     0	     0
#Predicted	phase2	     1	     0	     9	     0	     0	     0
#         	phase3	     0	     0	     0	    14	     0	     0
#         	phase4	     1	     0	     0	     0	     7	     0
#         	phase5	     0	     0	     0	     0	     0	     0
i,time,loss,ground_time,compile_time,eval_time
100,11.141002655029297,0.35660948878574344,0.0017727717876434,0.00650024418830881,0.0003129202842712394
200,22.955020904541016,0.2329929453848672,0.00179080643653867,0.006327634382248052,0.00033515377044677797
300,35.11537408828735,0.2098662495816393,0.001782671689987146,0.006604120588302736,0.0003446434020996097
400,50.90404725074768,0.19483530686163647,0.0018173138141631764,0.006376169013977167,0.00044434022903442407
500,64.39071702957153,0.20066079369360323,0.001799436330795251,0.006616016244888413,0.000392215681076051
600,78.36788654327393,0.20159005853861303,0.001759609460830653,0.0066269231796265695,0.0004071325778961183
700,92.76941537857056,0.19435350028453793,0.0017862791061400997,0.006414421939849964,0.0004168328285217289
800,107.59375023841858,0.19552874712707935,0.0018025306224822716,0.006517611265182615,0.0004227918624877937
900,124.1052634716034,0.1973674275708621,0.001829667377471888,0.006385034132003892,0.00046961708068847725
1000,135.75897455215454,0.19750693440258096,0.0018060494899749386,0.006581473064422744,0.0003175522804260258
1100,147.45261597633362,0.19657480960856696,0.0017907005786895497,0.006401849126815913,0.0003166438579559318
1200,161.7166986465454,0.195050566422983,0.0017930606365203572,0.006463403987884638,0.00039005489349365165
1300,175.0443572998047,0.18988665874562755,0.0017765678882598552,0.0064576288223267605,0.00036792759895324647
1400,189.52627062797546,0.19409972386341198,0.0018223628044128095,0.006275164747238274,0.00040450553894042944
1500,202.21709084510803,0.19933509527535406,0.0018094327449798267,0.006541422939300645,0.0003491181373596197
1600,216.105623960495,0.1892363921712579,0.0017915190219878854,0.006411198186874516,0.00038855552673339877
1700,229.7200255393982,0.19809116684617173,0.0018380200862884199,0.006454035472869982,0.0003747868537902845
1800,245.36039924621582,0.19433263055495537,0.001828077268600429,0.00642704844474805,0.00043190588951110833
1900,258.8260669708252,0.19322068112997626,0.0017973147392272618,0.006418934202194339,0.00037523379325866616
2000,270.2345061302185,0.1930242951211968,0.0018171755790710128,0.00637178411483775,0.0003158915519714358
2100,281.5545823574066,0.2011162600542312,0.001804652643203703,0.0064742395401002,0.00031116271018981876
2200,293.0601739883423,0.1950967661479995,0.0018292100429534613,0.006360489940643432,0.00031580381393432545
2300,304.7252004146576,0.20018041249896895,0.0017830118179320961,0.006622226953506583,0.00032269988059997756
2400,318.2215805053711,0.19900788458350122,0.001821888780593838,0.006447127485275385,0.0003814772129058841
2500,327.88652443885803,0.19562611524758794,0.0018284712314605444,0.006390736865997408,0.0002912611007690424
2600,336.90311098098755,0.1941513786807603,0.001867273473739588,0.006339642715454223,0.00027743196487426753
2700,345.5897264480591,0.1965333719073082,0.0018033228874206211,0.006504675769806021,0.00026524133682250906
2800,353.6895830631256,0.19511119275532962,0.0017976442813872936,0.006511011886596817,0.0002481583118438718
2900,362.1282260417938,0.18758275672111968,0.0018729374885558781,0.006454163837432962,0.00025698957443237287
3000,372.39533972740173,0.19224456855597893,0.0017532069683074717,0.006390728712082016,0.00031580839157104463
3100,383.50644874572754,0.19380506778526457,0.0017885243415832121,0.006538743448257563,0.0003414425373077396