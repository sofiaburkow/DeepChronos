#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#
#=== Results for full dataset ===
#
#Accuracy: 0.9996
#Micro F1: 0.9996 | Macro F1: 0.9607 | Weighted F1: 0.9996
#
#Per-class metrics:
#  [benign] P=0.9993 | R=0.9999 | F1=0.9996 | Support=20900
#  [phase1] P=0.8889 | R=1.0000 | F1=0.9412 | Support=8
#  [phase2] P=0.8750 | R=0.7778 | F1=0.8235 | Support=9
#  [phase3] P=1.0000 | R=1.0000 | F1=1.0000 | Support=14
#  [phase4] P=1.0000 | R=1.0000 | F1=1.0000 | Support=7
#  [phase5] P=1.0000 | R=0.9996 | F1=0.9998 | Support=29389
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase1	phase2	phase3	phase4	phase5
#         	benign	 20897	     0	     2	     0	     0	    13
#         	phase1	     1	     8	     0	     0	     0	     0
#Predicted	phase2	     1	     0	     7	     0	     0	     0
#         	phase3	     0	     0	     0	    14	     0	     0
#         	phase4	     0	     0	     0	     0	     7	     0
#         	phase5	     1	     0	     0	     0	     0	 29376
i,time,loss,ground_time,compile_time,eval_time
100,8.147104501724243,0.0006131336234445839,0.004427530670166057,0.004301739645004318,0.0002246432304382322
200,16.12150001525879,4.053742797781368e-05,0.00449410595893863,0.004370107030868566,0.0002217532157897951
300,23.91964340209961,5.3878545882928285e-05,0.004399689912796076,0.004255403852462812,0.0002165307998657229
400,31.43268394470215,2.7698813178826943e-05,0.004392116641998342,0.004242232131958046,0.00020888247489929214
500,38.966450691223145,3.770992497006409e-05,0.004610768938064617,0.00451725015640263,0.00020872502326965296
600,46.55124306678772,0.0009285282346935375,0.0043191400051117565,0.004150196313858085,0.00021050219535827735
700,54.11848020553589,3.6168775783329554e-05,0.004348355913162264,0.004189914131164587,0.00020878558158874473
800,61.71026039123535,3.269517041294856e-05,0.004299399232864423,0.004123754405975355,0.00020976815223693794
900,69.27410554885864,5.337116973452849e-05,0.004374132680892981,0.004223099565506022,0.0002087092399597172
1000,76.85935568809509,0.00091362347410761,0.004475668001174974,0.004349720430374199,0.00020920481681823737
1100,84.44904136657715,5.1631489459849076e-05,0.004504052972793624,0.0043838448047638385,0.00020884537696838412
1200,92.09839653968811,1.8169091443716035e-05,0.004235839986801205,0.004048260641098067,0.00020982770919799866
1300,99.735675573349,2.3627116741242737e-05,0.00461672635078435,0.00452493753433235,0.00021044979095458948
1400,107.4120352268219,3.19220692372757e-05,0.00441132426261907,0.004265356492996263,0.00021075458526611295
1500,115.06952285766602,3.679376283583835e-05,0.004413168907165579,0.0042724890708923996,0.00021016564369201628
1600,122.71758580207825,3.6173682186091403e-05,0.004401851177215624,0.0042559063911438546,0.00020909647941589363
1700,130.3497552871704,0.0007234067442718617,0.004621735048294117,0.004533731508255065,0.0002098125457763676
1800,137.93586206436157,3.0313835334656592e-05,0.00440640377998355,0.0042599368572235384,0.00020771017074584983
1900,145.55271863937378,2.0427660054831433e-05,0.004506872510910076,0.004387623071670583,0.00020865707397460932
2000,153.15625667572021,0.0004512224207404958,0.004581036472320591,0.0044831792831421385,0.00020843462944030718
2100,160.77890181541443,2.44699406488591e-05,0.004375819921493581,0.004223330259323162,0.00020861930847167906
2200,168.40483856201172,0.000209772721585062,0.004517859745025687,0.00440135731697086,0.00020899643898010222
2300,176.0821635723114,0.0009573826209073966,0.004440662145614688,0.004302521038055472,0.00021061081886291554
2400,183.70050430297852,4.5869812131877906e-05,0.004460058927536069,0.004329493474960372,0.0002085839748382563
2500,191.32199668884277,7.497239195188853e-05,0.004507454347610508,0.0043882960319519305,0.00020846004486083973
2600,198.9674973487854,0.0025699500817199495,0.004365920639038144,0.004210318708419846,0.0002091123104095452
2700,206.59596276283264,0.0008059285760061252,0.004411260366439882,0.0042685985088348885,0.00020843834877014273
2800,214.23519086837769,5.2587086637028155e-05,0.004335528612136909,0.004172163772583053,0.00020900673866271937
2900,221.85667061805725,3.627988901192314e-05,0.004430882406234778,0.004291912174224919,0.00020826511383056613
3000,229.49395751953125,0.0007296989043673796,0.004462168931961116,0.004330266952514709,0.00020890498161315962
3100,237.0979039669037,5.9521295612336986e-05,0.0045776223182678825,0.004475662231445354,0.0002083995819091789
3200,244.72683238983154,0.000503113531384416,0.004437277555465741,0.0043006814002991165,0.00020858407020568864
3300,252.35331916809082,9.458463948148532e-05,0.004539118099212706,0.004429657506942816,0.00020858373641967823
3400,260.0155117511749,2.388034553883811e-05,0.004481708765029938,0.004355643129348804,0.00020912699699401902
3500,267.6713478565216,1.9965257887593068e-05,0.004636594772338924,0.004552319526672414,0.0002087517261505124
3600,275.3067030906677,0.0034222935022417155,0.004353025341033976,0.004194727325439516,0.0002082398414611814
3700,282.93337512016296,2.8994896381671076e-05,0.004535608339309721,0.004424141550064129,0.00020909957885742214
3800,290.6289119720459,1.8153459748266876e-05,0.0045349462985993,0.004421968841552788,0.0002116818904876714
3900,298.23253107070923,0.0007654720244676083,0.004400525188446088,0.00425434770584111,0.00020822353363037099
4000,305.8625154495239,3.969985187506353e-05,0.004327444171905556,0.004163612937927286,0.00020992350578308023
4100,313.45382142066956,4.780280192573594e-05,0.004493943595886267,0.004370467329025303,0.00020847296714782699
4200,321.07049226760864,2.8762540034585894e-05,0.0045668841362000116,0.004462691688537632,0.00020856623649597169
4300,328.7268123626709,4.4510897705305476e-05,0.004386693429946931,0.0042369607448578175,0.00020977001190185577
4400,336.3688530921936,2.573820405306737e-05,0.004461098003387498,0.004329259300231979,0.00020862336158752445
4500,344.0923352241516,5.077378251753695e-05,0.004398229932785089,0.004250854778289833,0.00021039652824401852
4600,351.74738931655884,0.0022805263063494976,0.0045868735313416,0.00448860034942633,0.00020886096954345727
4700,360.902551651001,0.0010959445686474579,0.004550069761276295,0.00444306473731999,0.00024409379959106442
4800,378.56112027168274,0.00024109835482119201,0.004385823726654089,0.004236524343490652,0.0004437528133392342
4900,396.2520396709442,4.6502789332940606e-05,0.00434653029441839,0.004185952234268239,0.0004433615207672121
5000,413.9328112602234,4.232097566689852e-05,0.004368409872055098,0.004213373184204147,0.0004438923358917245