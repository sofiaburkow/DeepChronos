#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#
#=== Results for full dataset ===
#
#Accuracy: 0.9978
#Micro F1: 0.9978 | Macro F1: 0.6879 | Weighted F1: 0.9983
#
#Per-class metrics:
#  [benign] P=0.9992 | R=0.9955 | F1=0.9973 | Support=20900
#  [phase1] P=0.7273 | R=1.0000 | F1=0.8421 | Support=8
#  [phase2] P=0.1500 | R=1.0000 | F1=0.2609 | Support=9
#  [phase3] P=0.4118 | R=1.0000 | F1=0.5833 | Support=14
#  [phase4] P=0.3000 | R=0.8571 | F1=0.4444 | Support=7
#  [phase5] P=0.9998 | R=0.9995 | F1=0.9996 | Support=29389
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase1	phase2	phase3	phase4	phase5
#         	benign	 20805	     0	     0	     0	     1	    16
#         	phase1	     3	     8	     0	     0	     0	     0
#Predicted	phase2	    51	     0	     9	     0	     0	     0
#         	phase3	    20	     0	     0	    14	     0	     0
#         	phase4	    14	     0	     0	     0	     6	     0
#         	phase5	     7	     0	     0	     0	     0	 29373
i,time,loss,ground_time,compile_time,eval_time
100,7.76261568069458,0.5879711792850867,0.004202629566192663,0.004371656799316318,0.00022030496597290057
200,15.293348550796509,0.3334850260557141,0.0043964006900787745,0.004628997993469156,0.00021599130630493168
300,22.811486959457397,0.17981730000989046,0.004360120010376,0.004579842090606597,0.00021476831436157264
400,30.312657594680786,0.14440793040499555,0.004305030584335359,0.00450105633735649,0.0002142552852630618
500,37.8770387172699,0.11303449771367013,0.004390058946609524,0.004618871641158978,0.0002169556140899652
600,45.332252979278564,0.10536062309358385,0.00442985858917238,0.004674277734756373,0.00021409502029418924
700,52.81595587730408,0.08977450384627446,0.004530564594268826,0.004819259309768599,0.00021506767272949157
800,60.313740491867065,0.06921417016721534,0.004549235439300577,0.004840886402130035,0.00021510400772094759
900,67.81494522094727,0.06703873749520425,0.0041771604537964285,0.004319167613983092,0.00021475424766540524
1000,75.30893015861511,0.05088563429739224,0.004334497451782255,0.004540656280517498,0.00021418623924255358
1100,82.81226205825806,0.043343008966112394,0.004325378131866504,0.0045271461486815654,0.00021396255493164054
1200,90.33425331115723,0.042556676854019315,0.004450329160690341,0.00470721530914297,0.00021364703178405824
1300,97.84263706207275,0.04350763979261501,0.004351599693298386,0.004568261146545365,0.00021438570022583043
1400,105.36725640296936,0.03262960159261638,0.004324827480316188,0.004525966548919596,0.00021385011672973714
1500,112.93225002288818,0.03239120338333123,0.004294216966629055,0.004486386394500652,0.00021427845954894988
1600,120.53114080429077,0.023403091929417315,0.004277409982681305,0.004462186861038136,0.00021570315361022911
1700,128.0975592136383,0.02107756083349159,0.004352713298797628,0.00456883783340446,0.0002147906303405757
1800,135.64490628242493,0.02209101742452276,0.004317205619812043,0.004520375537872236,0.00021487698554992655
1900,143.20444989204407,0.017296199135973894,0.004241459560394314,0.004408025074005039,0.00021454820632934514
2000,150.8532907962799,0.018574101064430124,0.004352759027481104,0.004569877338409332,0.00021572604179382316
2100,158.4463448524475,0.011604491593475359,0.00429051337242132,0.0044817969322203935,0.0002151440620422366
2200,169.8461410999298,0.015965852675872156,0.0043747881889343665,0.004599204397201479,0.00031464552879333557
2300,186.97148394584656,0.007160280873329157,0.004349851083755545,0.004564602708816468,0.00046290898323059145
2400,204.20853066444397,0.011048274865202075,0.004318824958801314,0.004520874977111748,0.0004625058174133305
2500,221.5465362071991,0.01304921152269344,0.0043014217376709405,0.004495955657958909,0.00046366605758667084
2600,238.79280614852905,0.006945369862831967,0.004331424427032506,0.004536261129379194,0.0004633344173431407
2700,255.97390961647034,0.0046686310265965855,0.004451939725875883,0.004704488420486362,0.0004634037494659426
2800,273.18676471710205,0.008429288234676733,0.004556846380233793,0.004855043220519926,0.000463389110565185
2900,290.3677091598511,0.005348160390768726,0.004323972463607823,0.004530179738998336,0.00046330356597900404
3000,307.5410113334656,0.008045019681667327,0.00441227116584782,0.0046493451118468435,0.000462950992584229
3100,324.6608340740204,0.006214948929932689,0.0044108057022095165,0.004648775243759081,0.00046228880882263304
3200,341.8260672092438,0.0062561962660305425,0.0044317882061004924,0.004678429841995168,0.0004628787040710445
3300,359.17110896110535,0.007374275545100204,0.004559496402740511,0.004855426502227699,0.0004639078140258797
3400,376.56288838386536,0.0038282656711362507,0.004285973978042635,0.004472494029998689,0.0004636124610900888
3500,394.1409718990326,0.007824663033951539,0.0043418105125427545,0.004550885057449256,0.0004640475273132328
3600,411.6703209877014,0.004998500143961451,0.004342176008224516,0.004553708219528128,0.0004643399238586428
3700,429.01983523368835,0.0036746978337407654,0.004446222257614168,0.004698482322692781,0.00046411800384521475
3800,446.32145857810974,0.005747072285702756,0.0042739374637604036,0.0044564207553862865,0.00046343164443969734
3900,463.5980987548828,0.0049141026063890085,0.004402082729339626,0.004633913373947058,0.0004636397838592538
4000,480.89946842193604,0.005894587448843538,0.004229368257522608,0.004396254587173393,0.00046386184692382885
4100,498.1620764732361,0.00456757348563201,0.004420326519012478,0.004659541749954133,0.00046354117393493653
4200,515.57088971138,0.003044285784185092,0.004377545166015634,0.004603227949142368,0.0004638365745544437
4300,532.9892470836639,0.006598245534344187,0.004386538457870523,0.004614220952987587,0.00046360230445861904
4400,550.3051545619965,0.006014031088664638,0.004448236608505287,0.00469829559326164,0.0004637496471405025
4500,567.5499429702759,0.002990791509723465,0.004534296989440947,0.004825317668914706,0.0004629806041717524
4600,584.6755170822144,0.002053687422794326,0.004428305387496975,0.0046730240821837585,0.0004594016075134281
4700,602.0292680263519,0.007080693329872077,0.004350435638427771,0.004562275695800679,0.0004640383243560787
4800,619.4167852401733,0.004588168086356177,0.004407089614868203,0.004644053506851103,0.0004633615970611584
4900,636.8661742210388,0.0032144279622698946,0.0043720150470734,0.004594861793517988,0.000464097023010255
5000,654.3487873077393,0.00598334254021367,0.004279370069503823,0.004462897872924743,0.0004639734745025631