#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#Accuracy 0.7316433566433567
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase5	phase1	phase2	phase3	phase4
#         	benign	 36783	 13505	     0	     0	     0	     0
#         	phase5	     2	     1	     0	     0	     0	     0
#Predicted	phase1	     0	     0	     9	     0	     0	     0
#         	phase2	     0	     0	     0	    11	     0	     0
#         	phase3	     0	     0	     0	     0	    16	     0
#         	phase4	     1	     0	     0	     0	     0	     8
i,time,loss,ground_time,compile_time,eval_time
100,14.291711807250977,0.20221554942858624,0.0007866203784942428,0.0002408330440521182,0.00047867488861083883
200,23.89535427093506,0.20375207855833882,0.000796589088439919,0.0002504409313201838,0.00025536971092224005
300,34.334306716918945,0.21303796406236594,0.0007931802749633576,0.00022646837234496537,0.0002767821311950682
400,51.08382225036621,0.199551482036932,0.0007974948406219277,0.00023922705650329082,0.0004703666210174565
500,66.03405356407166,0.1852635308937609,0.0007939826011657496,0.0002353857517242371,0.00041913781166076755
600,80.4636287689209,0.18823878662943688,0.000793973207473733,0.00024345111846923184,0.00039959750175476053
700,98.31178879737854,0.18086344149168895,0.0007945194721221695,0.00023190240859984821,0.0004766239166259767
800,114.95391845703125,0.1839273001333333,0.0007958229541778349,0.00024317145347594612,0.00045375227928161484
900,131.5023627281189,0.18728843940920525,0.000792212772369367,0.00022140808105468193,0.00044740858078002726
1000,142.54737091064453,0.17997266962080402,0.0007941689014434588,0.00023576107025145946,0.000311023712158203
1100,167.8325433731079,0.17432167708276203,0.0007959193229675075,0.00023283314704894482,0.0007229884147644052
1200,177.7492904663086,0.17735143654993293,0.0007924742698669239,0.00023235917091369063,0.00028699107170104994
1300,185.86437010765076,0.18354536139387445,0.0007924756050109671,0.00022854719161986758,0.0002331414222717282
1400,193.30874300003052,0.19170976449264682,0.0007954572200774922,0.0002350299835205026,0.0002125783920288078
1500,200.77020645141602,0.18431474736628187,0.0007934576034545668,0.00023772020339965256,0.00021214632987976066
1600,207.93692898750305,0.17851790000992865,0.0007942565917968532,0.0002288495063781685,0.00020275659561157198
1700,215.35454869270325,0.18064957374175222,0.0007956927299499305,0.00023932662010192238,0.00021101331710815432
1800,222.57894229888916,0.18347652320127672,0.0008003290176391391,0.0002595308303832939,0.0002045411586761472
1900,231.54599618911743,0.1885918187805424,0.0007980871200561305,0.00025608768463134093,0.00025636463165283206
2000,239.3003797531128,0.1790025797145379,0.0007952878952026134,0.00023306980133056107,0.00021941919326782237
2100,246.4520707130432,0.17964192441231147,0.0007939879417419232,0.0002399895668029717,0.0002017710685729985
2200,254.38100266456604,0.18869511785026336,0.0007976290702819606,0.00024795393943785984,0.0002253669261932375
2300,261.32870984077454,0.18122919694695588,0.0007965657234191698,0.0002445554256439148,0.00019511542320251488
2400,268.3163278102875,0.17840882297846788,0.000797550678253155,0.0002436368465423525,0.00019565901756286644
2500,275.48355174064636,0.17607540606331348,0.0007948564529418709,0.00023642358779906648,0.00020165734291076705
2600,282.5564305782318,0.1880440585857013,0.0007938950538635054,0.00023919653892516475,0.00019785490036010743
2700,289.55142188072205,0.180365312716303,0.0007958834648132082,0.0002397182464599549,0.0001956053733825688
2800,296.4902296066284,0.18017136341249068,0.0007930753231048371,0.00022970290184020414,0.00019409818649291947
2900,303.48086071014404,0.18410659154307876,0.0007946120262145786,0.00024222741127013562,0.00019539146423339814
3000,310.4423496723175,0.1793649034663437,0.0007945676326751499,0.00023760232925414528,0.00019478521347045933
3100,317.6144347190857,0.1758160430044234,0.0007922014236449972,0.00022072176933288053,0.0002011981010437015