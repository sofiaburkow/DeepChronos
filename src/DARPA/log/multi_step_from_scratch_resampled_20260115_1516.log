#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#Accuracy 0.7314446916719644
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase5	phase1	phase2	phase3	phase4
#         	benign	 36776	 13506	     0	     1	     0	     1
#         	phase5	     0	     0	     0	     0	     0	     0
#Predicted	phase1	     0	     0	     9	     0	     0	     0
#         	phase2	     1	     0	     0	    10	     0	     0
#         	phase3	     3	     0	     0	     0	    16	     0
#         	phase4	     6	     0	     0	     0	     0	     7
i,time,loss,ground_time,compile_time,eval_time
100,10.769593238830566,0.3202821648332383,0.001047312355041543,0.0010821070194244173,0.0002965236663818356
200,19.14388656616211,0.2119339425095262,0.0010536525726318705,0.0010508308887481454,0.000253193235397339
300,28.59542441368103,0.20607937957173547,0.0010569128990173717,0.0010955206394195323,0.00028780031204223683
400,42.21889019012451,0.19591487457670356,0.0010569444179535264,0.0010962372303008777,0.00039223365783691366
500,52.1002995967865,0.19392508432041045,0.0010603471279144695,0.0011211962699889855,0.0002977723598480222
600,60.7179000377655,0.18970147803063417,0.0010508638381958413,0.0010121970176696516,0.00025978531837463287
700,69.22582578659058,0.18737149215523607,0.0010544419765472783,0.001072740030288672,0.00025558500289916996
800,78.85844564437866,0.18806634887597692,0.0010519846916199089,0.0010141981124877763,0.0002845320701599112
900,89.40768671035767,0.18334396375665057,0.0010529778957367277,0.0010317532539367439,0.0003058698654174806
1000,98.91882801055908,0.1848440389718098,0.0010544124126434717,0.0010483732700347658,0.00028304600715637143
1100,108.65415811538696,0.18409831203498453,0.0010551369667053591,0.0010442955493926767,0.00028420219421386683
1200,118.05613017082214,0.17717264393842158,0.0010556049823761352,0.0010440811634063465,0.00027712812423706066
1300,127.3302252292633,0.17304594037263374,0.0010535255908966415,0.001054019498825048,0.00027476000785827683
1400,136.19959664344788,0.19116624020281656,0.0010552504062652935,0.001054141664504981,0.00026420760154724146
1500,145.36653876304626,0.19191536192236391,0.0010567275047302623,0.0010490866184234401,0.0002718605041503905
1600,155.1344349384308,0.18656657763154452,0.0010568014621735022,0.001029733371734598,0.0002880148410797113
1700,164.65564894676208,0.18585600293880383,0.0010571250915527713,0.0010762894153594708,0.00027863926887512265
1800,173.96099138259888,0.18689583867488568,0.0010571928501129529,0.0010818834781646507,0.0002755973815917966
1900,183.3026578426361,0.1811862950873892,0.0010565718173981087,0.0011000544071197243,0.0002771282672882081
2000,193.01606822013855,0.18095618128716212,0.0010573765277862898,0.0010995773315429426,0.0002853118896484371
2100,203.51175546646118,0.18378325336121154,0.0010555357933044812,0.0010769510746001948,0.0003061665058135984
2200,218.95169806480408,0.18145104915980778,0.0010536629199982047,0.00102729425430296,0.0004196761608123781
2300,234.55712127685547,0.1847206016526594,0.0010565892696380989,0.0010588387966155757,0.00042217040061950836
2400,242.4154896736145,0.17842987427348578,0.0010567495822906838,0.0010822563648223665,0.00023426675796508808
2500,250.10580968856812,0.1734458593809816,0.001055246353149452,0.0010706249713897467,0.00022830185890197803
2600,257.9270613193512,0.18001072904125234,0.001054805421829257,0.0010629344463348117,0.0002323153972625733
2700,269.541868686676,0.18107571254024318,0.0010545522212982528,0.0010568801879882576,0.00031510329246521015
2800,281.9654142856598,0.19310197475791605,0.0010539088249206909,0.0010046657562255644,0.00032773499488830617
2900,294.60977602005005,0.18062245511941977,0.0010533457279205654,0.0010360809326171675,0.00033186130523681616
3000,307.87091970443726,0.181211695920674,0.001053144550323523,0.0010904546260833501,0.0003656678676605233
3100,315.67339873313904,0.1790253974117309,0.00105643239021305,0.0011003873348235807,0.00022508983612060533