#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#Accuracy 0.9998013350286078
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase5	phase1	phase2	phase3	phase4
#         	benign	 36776	     0	     0	     0	     0	     0
#         	phase5	     0	 13506	     0	     0	     0	     0
#Predicted	phase1	    10	     0	     9	     0	     0	     0
#         	phase2	     0	     0	     0	    11	     0	     0
#         	phase3	     0	     0	     0	     0	    16	     0
#         	phase4	     0	     0	     0	     0	     0	     8
i,time,loss,ground_time,compile_time,eval_time
100,9.44632363319397,0.6301022586924955,0.0008570161342620327,0.0026636474609375354,0.00023815937042236405
200,18.66515612602234,0.34488681848160924,0.000868465089797925,0.0027300734519958786,0.00023187580108642564
300,28.092977285385132,0.10868927753908793,0.0008666649818419906,0.002691219949722325,0.0002338574409484867
400,37.77192187309265,0.039517502082017014,0.0008679869651793905,0.0027163733005524083,0.00023515238761901816
500,47.127158880233765,0.01914645298344112,0.0008665902614592997,0.002694035291671795,0.0002321848392486575
600,56.43298602104187,0.01286966016963561,0.0008679639339446507,0.0027308911800384876,0.00023263907432556142
700,65.91825199127197,0.009892414310816094,0.000870564460754341,0.002746118688583402,0.00023477573394775362
800,75.45050120353699,0.007478408769429734,0.0008664183616637657,0.002703461313247725,0.00023404412269592271
900,84.9443724155426,0.005676552876484493,0.000865410232543895,0.002659048080444371,0.00023476247787475513
1000,94.44919896125793,0.00408097563416959,0.0008694584846496043,0.002749240016937293,0.00023399238586425795
1100,103.87155532836914,0.0033663458492128482,0.0008700610637664264,0.0027350741863251,0.0002331492900848377
1200,113.34265637397766,0.0035731146149146297,0.000869063091278026,0.0027548238754272754,0.00023289809226989693
1300,123.07943987846375,0.003272548908691988,0.0008673945426940409,0.0026886297225952515,0.00023601021766662535
1400,132.55353665351868,0.00270837372270762,0.0008714761257171102,0.0027778122901916708,0.00023199691772460962
1500,142.24032425880432,0.0018804129839782035,0.0008703689575194786,0.0027760062217712734,0.00023638463020324665
1600,152.4983251094818,0.0025101021621514973,0.0008674431800841766,0.0026969164371490827,0.000256885766983032
1700,162.03642296791077,0.002484593551545231,0.0008647305488585911,0.0026538671970367882,0.00023466405868530213
1800,171.2106273174286,0.0008586196200138829,0.000864648199081373,0.002656708574295087,0.00023078413009643562
1900,180.5754735469818,0.0016305385098098668,0.0008698241233825166,0.002773464870452911,0.0002344437122344968
2000,189.95985889434814,0.0006796271308650148,0.0008662508964538069,0.0026933851242065907,0.00023436889648437498
2100,199.31023144721985,0.0021130889788832973,0.0008660615444182825,0.0026610546588898094,0.0002319602966308594
2200,208.85914492607117,0.0005396464339997919,0.0008668025493621334,0.002692496919631996,0.00023395161628723095
2300,218.1935703754425,0.0017207176041353022,0.0008690477371215288,0.002736587238311804,0.00023142652511596635
2400,227.4787724018097,0.0005119836381518894,0.0008655083656310525,0.00268897628784184,0.00023142404556274413
2500,236.75318694114685,0.0004643616728972688,0.0008713192462920616,0.0027826847553253462,0.00023130784034729017
2600,246.1019251346588,0.0004314052064700036,0.0008667408943175746,0.0026979362010956256,0.00023221220970153717
2700,255.73596930503845,0.00036702891907822274,0.0008669571399688218,0.0026952604770660755,0.0002352539539337159
2800,265.37578201293945,0.0015662826802628161,0.0008651742458342976,0.0026581037521362745,0.0002344979286193849
2900,274.89922857284546,0.0003208974588025626,0.0008694452285766081,0.0027467354297638293,0.0002345123291015631
3000,284.47092366218567,0.0005129146693477083,0.0008651015758513916,0.002677812385559126,0.00023446722030639626
3100,294.0566189289093,0.00023923847576270418,0.0008689889907836383,0.0027344325065613052,0.00023404355049133217