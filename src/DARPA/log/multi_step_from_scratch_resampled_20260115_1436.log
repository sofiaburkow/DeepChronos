#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#Accuracy 0.7223657024793388
#Confusion Matrix:
#         	      	      	      	Actual	      	      	      
#         	      	benign	phase5	phase1	phase2	phase3	phase4
#         	benign	 36319	 13506	     0	     2	     0	     0
#         	phase5	     0	     0	     0	     0	     0	     0
#Predicted	phase1	     0	     0	     9	     0	     0	     0
#         	phase2	   110	     0	     0	     9	     0	     0
#         	phase3	   220	     0	     0	     0	    16	     0
#         	phase4	   137	     0	     0	     0	     0	     8
i,time,loss,ground_time,compile_time,eval_time
100,8.065999507904053,0.5800441691838205,0.0009909610748290688,0.0009929244995117686,0.00023760118484497116
200,17.724833965301514,0.4153223154658917,0.0010023867130279202,0.0010390238285065258,0.00028988475799560597
300,26.719995975494385,0.28263242772067315,0.0010028140544891021,0.0010378957748413626,0.00026346044540405297
400,33.93380928039551,0.24681417778454487,0.0010011693954467458,0.001002912139892629,0.00021407594680786132
500,41.30636286735535,0.24307936466524552,0.0010022573471068987,0.0010508082389832085,0.00021885151863098196
600,51.20433497428894,0.23353460022357467,0.0010039617538451823,0.0010519229412079489,0.00029380798339843786
700,58.80031943321228,0.2227507826531655,0.0009990347862243309,0.0009816599845886781,0.00022537803649902286
800,67.12485027313232,0.2369028253057968,0.0010020053386687903,0.0009838037967682429,0.0002492599487304692
900,76.53675580024719,0.22191363143187118,0.0010027521133422514,0.0010270922660828212,0.0002790880680084219
1000,87.1441810131073,0.21636206261131974,0.0010027262210845608,0.0010385382175446191,0.00030945901870727585
1100,93.93403625488281,0.20871552954522485,0.0010023840904235485,0.0010453828811646134,0.00019976158142089858
1200,111.27871608734131,0.20600845310051683,0.0009994242668151534,0.0009934140682221033,0.000492607784271241
1300,141.50499415397644,0.20716158437596732,0.0010031063079833638,0.0010492499351502107,0.0009224233150482156
1400,171.92377257347107,0.2016558700257383,0.0010043971061706248,0.0010389936447144105,0.0009174443244934084
1500,199.30329179763794,0.20141973510372055,0.0010032577037810944,0.0010494185924530594,0.0008242700576782204
1600,209.36549544334412,0.20041108994043838,0.0010026447772979372,0.0010611564159393946,0.00030567898750305154
1700,220.07589173316956,0.19418663906401662,0.001000634288787806,0.00099645171165471,0.000328292798995971
1800,228.54368686676025,0.19466803081774856,0.0010026575565337801,0.0010595525741577778,0.00025692663192749003
1900,237.89608073234558,0.20121625576442057,0.001001334905624357,0.0010454288482666615,0.00028411092758178673
2000,247.08122158050537,0.2008098390380576,0.0010045951366424227,0.0010705514431000361,0.0002738247871398929
2100,255.87696051597595,0.19429252227012228,0.0009988231658935216,0.0009936228752136787,0.0002658265590667731
2200,264.21117401123047,0.18794451432851247,0.0010025819301604875,0.0010188644409180243,0.00024988846778869654
2300,274.1824631690979,0.18467233426354823,0.0010002023220061931,0.0010238833904266918,0.0003032989501953129
2400,284.06470465660095,0.18417785771154171,0.0010023802280425672,0.0010804960727692301,0.0003031631469726571
2500,292.6808214187622,0.19047640949770767,0.0010035052299499179,0.0010112654685974678,0.0002580555438995364
2600,301.8337469100952,0.18872330445204114,0.0010048249721526725,0.0011206671714783364,0.0002754624843597406
2700,311.73203110694885,0.19204737165365202,0.0010012423038482348,0.0010516493320465738,0.0002997214794158935
2800,340.3427109718323,0.18627251280941948,0.0010028739929198905,0.001041364574432429,0.0008376996040344221
2900,369.26183462142944,0.1883260603774039,0.0010026206016540186,0.001011171197891288,0.0008525425434112547
3000,398.79136753082275,0.18657435614960577,0.001005059289932217,0.0010801984310150768,0.0008699641704559319
3100,428.7185537815094,0.18457126544544933,0.0010005104541778228,0.0010094066143036399,0.00087692985534668