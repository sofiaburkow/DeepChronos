#{"solver": {"engine": {"type": "ExactEngine"}, "semiring": "GraphSemiring"}, "networks": [{"name": "net1", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net2", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net3", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net4", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}, {"name": "net5", "module": "FlowLSTM(\n  (softmax): Softmax(dim=1)\n  (lstm): LSTM(112, 64, batch_first=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=2, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "k": null}], "program": "nn(net1,[X],Z,[benign, phase1])::phase(1,X,Z).\nnn(net2,[X],Z,[benign, phase2])::phase(2,X,Z).\nnn(net3,[X],Z,[benign, phase3])::phase(3,X,Z).\nnn(net4,[X],Z,[benign, phase4])::phase(4,X,Z).\nnn(net5,[X],Z,[benign, phase5])::phase(5,X,Z).\nmulti_step(X,P1,P2,P3,P4,Outcome) :- Next is P1+P2+P3+P4+1, phase(Next,X,Outcome).\n"}
#Accuracy 0.9993641584040376
#Confusion Matrix:
#         	      	      	      	Actual	      	      
#         	      	benign	phase2	phase3	phase4	phase5
#         	benign	 36793	     0	     0	     0	     0
#Predicted	phase2	     9	     0	     0	     0	     0
#         	phase3	    14	     0	     0	     0	     0
#         	phase4	     9	     0	     0	     0	     0
#         	phase5	     0	     0	     0	     0	 13502
i,time,loss,ground_time,compile_time,eval_time
100,7.910031318664551,0.7240701218135654,0.0023334570407869616,0.00959076404571419,0.0002444579601287847
200,17.106181859970093,0.3072422108438332,0.0023442883491518315,0.00960816402435187,0.0002847826957702639
300,27.34576177597046,0.03131919311563251,0.002349354171753155,0.009634120082854067,0.00031470017433166494
400,36.64683651924133,0.010877454758738168,0.002346396017074802,0.009618569850920473,0.00028871202468872014
500,45.962480306625366,0.005757073915810906,0.002332887268066624,0.009536109542845539,0.00028758544921874974
600,55.166372299194336,0.0038867835009659757,0.002337587547302463,0.00956446433067207,0.0002866980552673351
700,64.7855589389801,0.0030594019103227766,0.0023492856025698005,0.009636592292784482,0.0003003533840179438
800,77.19072985649109,0.0028018484840140446,0.002340279960632544,0.00957747616767768,0.00038559060096740664
900,105.92680096626282,0.0018521921338651736,0.002336349153518897,0.009556740427016059,0.0008966779232025153
1000,126.48275017738342,0.001759404474414623,0.00237697305679344,0.009809087467192413,0.0006255446910858137
1100,139.8827486038208,0.000929166033220099,0.0023433054924013453,0.00960297946929816,0.0003876423358917225
1200,155.1981840133667,0.0010719309039632207,0.0023452785491945576,0.009613346624373232,0.00044203772544860754
1300,168.2250213623047,0.0012264578274789528,0.002334857463836887,0.009546475696562558,0.0003814695835113522
1400,177.13571310043335,0.0011715120139251668,0.002329063606262422,0.00951043472289925,0.00027342934608459474
1500,186.9622552394867,0.0006338184438936878,0.0023451212882997802,0.009613311338423535,0.0002987374305725099